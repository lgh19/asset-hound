## Operational Handbook for the Asset Map + Database

The objective of this project is to join many datasets from federal, state, and local sources to synthesize a comprehensive picture of the assets that make up the infrastructure of a particular community.

### Source-file preparation
We assembled many such datasets, in some cases filtering them down to just those in Allegheny County, or even filtering into several different files, one for each of the types of assets in the original file.

The source files can be found in [this private repository](https://github.com/WPRDC/liquid-assets). Source files are typically either CSV files, Excel files (which are then converted to CSV files using Visidata), or ESRI shapefiles (which are converted to SQLite using [shapefile-to-sqlite](https://pypi.org/project/shapefile-to-sqlite/), and from there to CSV, again by Visidata).

### Conversion to a standard schema
[This ETL script](https://github.com/WPRDC/rocket-etl/blob/master/engine/payload/asset_map/_facet_hound.py) can be run (after setting the parameter `one_file` to `True`) to process all the source files represented in the `job_dicts` list, using the corresponding schemas, to produce an `all_assets.csv` file, which contains all the asset information in a standard schema, suitable for uploading to the asset database. This command will process all the source files:

```> python launchpad.py engine/payload/asset_map/_facet_hound.py mute``` 

The job codes defined in the `job_dicts` list can be supplied as command-line arguments to generate a file containing just those assets. For instance, the `job_code` value for the public-art dataset is `public_art`, so running

```> python launchpad.py engine/payload/asset_map/_facet_hound.py mute public_art```
will only process the public_art job. If `one_file == False`, the generated file will be called `public-art-pgh.csv` and will only contain the fields defined by the corresponding schema (whereas when `one_file == True`, all fields in the asset schema are included in the file). All converted files will be saved to the directory given in the variable `ASSET_MAP_PROCESSED_DIR`, as specified by the `destination_file` parameter in the jobs (though this could be changed).

The contents of these files are considered to be raw assets.

### Uploading raw assets to the asset database and then downloading them

The asset database (defined in [this Django models.py file](https://github.com/WPRDC/asset-hound/blob/master/assets/models.py)) has a RawAsset model which is compatible with the schema produced by the `_facet_hound.py` ETL job. To upload a file of raw assets, converted by `_facet_hound.py`, move the file to the assets server (`> sftp all_assets.csv <username>@assets.wprdc.org:<path-to-asset_hound>/raw_assets_to_add.csv`), shell into the Django server, change directories to the Django directory, activate the Django virtual environment (`source env/bin/activate`), and run the RawAsset-loading management command (`> python manage.py load_raw_assets raw_assets_to_add.csv`).

The contents of the raw-asset table can then be exported from the database by running
```> python manage.py dump_raw_assets```

### Creating and editing assets
The resulting `raw_asset_dump.csv` file is then exported to another computer, where a subset of raw assets may be selected (for instance, all raw assets of a given asset-type (like `restaurants`)). This filtered file is run through a Python script that facilitates finding and merging raw assets. When the script finds sufficiently similar raw assets, it proposes them as duplicates to merge and the lets the user select among conflicting values on a field-by-field basis. The output of this process is what we call a merge-instructions file.

#### The format of the merge-instructions file

#### Some details about how the deduplication is done

### Updating Assets
Records in the Assets table can be modified in three ways: 1) Using the Django admin interface allows record-level modifications. This is fine for handling a few changes, but inefficient for bulk changes. 2) Making changes through the Django shell. This requires shelling into the assets server and making changes with Python commands. This can be powerful and fast but also tricky and unforgiving, requiring the user to manually take care of many things, and it only leaves documentation in the form of the history-tracking model. 3) The Asset updater, a web service that accepts merge-instructions files, allows them to be validated, automates much of the process, and tags any Asset edits with an identifiable "change_reason" field.

There are two different versions of the Asset updater. The original version uses merge instructions generated from a raw-asset dump file. 

[https://assets.wprdc.org/edit/update-assets/using-raw-assets/](https://assets.wprdc.org/edit/update-assets/using-raw-assets/)

This can be used to link one or more RawAssets to a new or existing Asset (where the Asset table is what is used to generate the asset map and to give details about the asset when the corresponding dot in the map is clicked) and to set the field values of that Asset. New Location and Organization instances can also be created through this process, as described on the [Asset updater page](https://assets.wprdc.org/edit/update-assets/using-raw-assets/).

The [Asset-based Asset updater](https://assets.wprdc.org/edit/update-assets/using-assets/) has similar functionality, but its merge-instructions file is generated from an asset dump file, which tells the updater which Assets how to edit Assets and how to merge existing Assets into existing Asset instances. When multiple Assets are merged into one, the others are "delisted", which means that their `do_not_display` value is set to `True`. The delisted Assets have their RawAssets reassigned to the single Asset that the others are merged into.

#### More about delisting
It is also the case that whenever an Asset is saved with no RawAssets pointing to it, it is automatically considered an unsupported Asset and therefore delisted. Delisting prevents an Asset from appearing on the map, but still allows it to persist in the database. Delisted Assets fall into two categories: 1) Those that have been delisted because they are not supported by links to any RawAssets. (These could in principle be deleted at some point, as could any orphaned Location or Organization instances that are not linked to any Assets.) 2) Those that are being hidden because we don't currently wish to show them (such as Assets outside of Allegheny County), but which we may wish to revive at some point (if we expand the map beyond Allegheny County). 

In contrast with Assets, RawAssets should normally not be deleted (or mutated) since they are a representation of the source file. If a RawAsset were deleted and then an update to the source data resulted in records being reuploaded as RawAssets, a RawAsset that had previously been set to not display could finds its way back on to the map. In principle, Assets that we wish to remove from the map could be deleted and their RawAssets set to `do_not_display = True`, but the approach that seems a more natural fit for our current workflow is to maintain the Asset (including its links to the RawAssets) but delist the Asset.

### Example workflow for adding a new file containing assets to the assets database
1) Convert the source file to a CSV file.
2) Edit a copy of [this ETL script](https://github.com/WPRDC/rocket-etl/blob/master/engine/payload/asset_map/_facet_hound.py) to add a schema and a `job_dict` entry in the `job_dicts` list. These specify how the fields in the source file map to the common asset-map schema. A `job_code` value should be given in the schema to allow the job (that is, the particular task of transforming the source file into another CSV file representing a particular set of assets) to be named from the command-line.
3) Set `one_file` to be `False` in the script.
4) Run the job like this: `> python ../../../launchpad.py asset_map/_facet_hound.py mute <job_code>`
5) A generated file with a name you provide (we'll suppose it's `new_assets.csv`) in the `job_dicts` entry should show up in the `processed` directory.
6) Transfer this file to the asset-map server (e.g., `> scp new_raw_assets.csv <your_username>@assets.wprdc.org:<path-where-you're-trying-to-put-the-file>`
7) Change to the asset-map backend directory and move the `new_raw_assets.csv` file there.
8) Run `> source env/bin/activate` to activate the virtual environment that supports Django.
9) Run `> python manage.py load_raw_assets new_raw_assets.csv` to load the raw assets into the database.
10) Run `> python manage.py dump_raw_assets` to dump the raw assets to a `raw_asset_dump.csv` file suitable for generating merge-instructions from.

### Exporting data
Accessing the URL [https://assets.wprdc.org/edit/dump_assets/](https://assets.wprdc.org/edit/dump_assets/) triggers a dump of the assets which will show up `(# of records)/(4000/minute)` later at
[https://assets.wprdc.org/asset_dump.csv](https://assets.wprdc.org/asset_dump.csv).

There is also a cronjob which periodically dumps the full set of assets to this file. This file is used as the source for the ETL job controlled by [this script](https://github.com/WPRDC/rocket-etl/blob/master/engine/payload/wprdc/assets_to_ckan.py), which runs nightly on the tools server.

### Carto integration
While there are REST API endpoints provided by the Django REST Framework, the server/database/API combination takes too long to pull the data for all assets to be used to supply data to the map on the frontend. Our current solution is to keep a narrow version of the assets table on Carto (with the important fields being asset name, asset type, category, latitude, longitude, `the_geom`, and `the_geom_webmercator`). This table is just a cache that fuels the map part of the frontend. When a user clicks on an asset marker on the front end, the assets database is queried to fill in the grey box with further details about the asset (like street address).

The entire assets database can be pushed to the Carto database by running a management command:

```> python manage.py sync_to_carto```

Individual asset types may be specified as command-line arguments to update just those asset types:

```> python manage.py sync_to_carto restaurants coffee_shops```

Also, the Asset save function has been modified to include a step wherein the corresponding row in the Carto table is updated/inserted/deleted, as appropriate. This involves four API calls (one to check whether the Asset ID already exists in the Carto table), one to do the updating/inserting/deleting, and two to update the geofields (since Carto does not automatically update the `the_geom` and `the_geom_webmercator` fields, but doing so is essential for updating the location of the map point. While this slows down Asset saves, it keeps the Carto map up-to-date and facilitates edits.

While this covers all Asset saves (and therefore all changes made through the Asset updater), changes made to a Location instance through the Django admin interface or Django shell will not currently trigger an updating of the Carto table. To cover these cases, the `sync_to_carto` management command is set to run daily at 1am, to entirely refresh the Carto table.

*Possible performance improvements:* Carto inserts are being done in batches as large as 100. Carto updates are being performed singly, but they could be rewritten to also be done in batches. Possibly experiment with adding Carto integration to Location saves.

